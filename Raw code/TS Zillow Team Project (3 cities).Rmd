---
title: "TS Zillow Team Project"
author: "Oleksiy Anokhin"
date: "10/29/2020"
output:
  html_document:
    toc: true
    toc_float: true
    toc_depth: 5
---

<center>
![](Images/Zillow.png)
</center>

### Introduction

This project uses data from [Zillow](https://www.zillow.com/research/data/) - an American online real estate database company.

The company provides access to its data - in particular, `Median Sale Price` (which is available in monthly and weekly views).

Our analysis is focused on `Median Sale Price` - the median price at which homes across various geographies were sold.

### Packages

```{r, message = FALSE, warning = FALSE}
# Install packages
library(tidyverse) # for general analysis
library(fpp)
# library(fpp2)
library(fpp3) # for predictions 
# Important notice: the latest package here is fpp3, but it does not work well sometimes with 'ts' data. 
# https://stackoverflow.com/questions/64348121/error-objects-of-type-ts-not-supported-by-autoplot-cannot-knit-rmarkdown-pack
# For example, I cannot use 'autoplot()' function for such data
# Hence, I will use fpp2 for this assignment
library(ggthemes) # for beautiful themes
# library(tinytex) # for pdf documents
# library(highcharter) # for beautiful charts
library(TSA) # for TS analysis
# library(readxl) # for xls files
library(kableExtra) # for beautiful tables
library(lubridate) # for time data
library(tsibble) # for tsiblle data format
# library(plotly) # for interactive charts
library(caret) # for modeling

# Set a theme
theme_set(theme_minimal())

# Remove scientific notations for prices
options(scipen = 999)
``` 

### ARIMA modelling procedure

When fitting an ARIMA model to a set of (non-seasonal) time series data, the following procedure provides a useful general approach.

- Plot the data and identify any unusual observations.

- If necessary, transform the data (using a Box-Cox transformation) to stabilise the variance.

- If the data are non-stationary, take first differences of the data until the data are stationary.

- Examine the ACF/PACF

- Try your chosen model(s), and use the AICc to search for a better model.

- Check the residuals from your chosen model by plotting the ACF of the residuals, and doing a portmanteau test of the residuals. If they do not look like white noise, try a modified model.

- Once the residuals look like white noise, calculate forecasts.

<center>
![](Images/Process.png)
</center>


### Import data

```{r, message = FALSE, warning = FALSE}
# Read data
sales <- read_csv("Metro_median_sale_price_raw_week.csv")

# Check dimensions
dim(sales)
```

#### Select Chicago data

```{r, message = FALSE, warning = FALSE}
# Read data
sales <- sales %>% filter(RegionName == "Chicago, IL" | RegionName == "Los Angeles-Long Beach-Anaheim, CA" | 
                          RegionName == "Dallas-Fort Worth, TX" | RegionName == "United States" )

# Check dimensions
dim(sales)
```

```{r, message = FALSE, warning = FALSE}
# # Read data for North
# sales_north <- sales %>% filter(RegionName == "Boston, MA" | RegionName == "Detroit, MI" | RegionName == "Minneapolis-St Paul, MN")
# 
# # Check dimensions
# dim(sales_north)
```

#### Preprocess data

```{r, message = FALSE, warning = FALSE}
# Convert data from wide to long format for proper analysis
sales <- sales %>% gather(key = "Date", value = "Price", -RegionID:-StateName) %>%
                   select(RegionName, Date, Price) %>%
                   rename(Metro_area = RegionName, Median_price = Price)

# Check dimensions
dim(sales)

# Print
kable(head(sales, n = 5)) %>% kable_styling() 
```


```{r, message = FALSE, warning = FALSE}
# # Convert data from wide to long format for proper analysis
# sales_north <- sales_north %>% gather(key = "Date", value = "Price", -RegionID:-StateName) %>%
#                                select(RegionName, Date, Price) %>%
#                                rename(Metro_area = RegionName, Median_price = Price)
# 
# # Check dimensions
# dim(sales_north)
# 
# # Print
# kable(head(sales_north, n = 5)) %>% kable_styling() 
```


```{r, message = FALSE, warning = FALSE}
# Convert date from character to date
sales$Date <- ymd(sales$Date)

# Print
kable(head(sales, n = 5)) %>% kable_styling() 
```


```{r, message = FALSE, warning = FALSE}
# # Convert date from character to date
# sales_north$Date <- ymd(sales_north$Date)
# 
# # Print
# kable(head(sales_north, n = 5)) %>% kable_styling() 
```


```{r, message = FALSE, warning = FALSE}
# Convert to tsibble object for time series analysis
sales <- as_tsibble(sales, key = Metro_area, index = Date)

# Check dataframe class
class(sales)
```


```{r, message = FALSE, warning = FALSE}
# # Convert to tsibble object for time series analysis
# sales_north <- as_tsibble(sales_north, key = Metro_area, index = Date)
# 
# # Check dataframe class
# class(sales_north)
```




#### Plot data

```{r, message = FALSE, warning = FALSE}
# Plot the initial data
sales %>% autoplot(Median_price, size = 1) +
                  facet_wrap(facets = "Metro_area", scales = "free", ncol = 1) + 
                  labs(title = "Median Sale Price in Chicago, Dallas, and LA Metro Areas", subtitle = "February 2008 - August 2020") +
                  xlab("Weekly data by year") + ylab("Median Sale Price") +
                  theme(legend.position = "none")
```

```{r, message = FALSE, warning = FALSE}
# # Plot the initial data
# sales_north %>% autoplot(Median_price, size = 1) +
#                   facet_wrap(facets = "Metro_area", scales = "free", ncol = 1) + 
#                   labs(title = "Median Sale Price in Boston, Detroit, and MSP Areas", subtitle = "February 2008 - August 2020") +
#                   xlab("Weekly data by year") + ylab("Median Sale Price") +
#                   theme(legend.position = "none")
```


#### Brief analysis

What can we see here?

- Visually data is non-stationary

- Two trends - downwarding and upwarding

- Seasonality exists

- The seasonal fluctuation of the line slightly decreases and increases in magnitude

### Plot AFC and PAFC

Why does `ACF` and `PACF` mean?

The function `Acf` computes (and by default plots) an estimate of the autocorrelation function of a (possibly multivariate) time series. 

Function `Pacf` computes (and by default plots) an estimate of the partial autocorrelation function of a (possibly multivariate) time series.^[Hyndman, R.J., (Partial) Autocorrelation and Cross-Correlation Function Estimation. Source: https://pkg.robjhyndman.com/forecast/reference/Acf.html. Retrieved on October 28, 2020]

```{r, message = FALSE, warning = FALSE}
# Plot ACF 
ggAcf(sales$Median_price, color = "#1277e1", size = 1) + 
      labs(title = "ACF plot for Median Sale Price in Chicago Metro Area", subtitle = "February 2008 - August 2020")
```

We definitely can see a very strong autocorrelation here. 

```{r, message = FALSE, warning = FALSE}
# Plot PACF 
ggPacf(chicago_sales$Median_price, color = "#1277e1", size = 1) + 
       labs(title = "PACF plot for Median Sale Price in Chicago Metro Area", subtitle = "February 2008 - August 2020")
```

#### KPSS test

what is KPSS and why do we need it?

One way to determine more objectively whether differencing is required is to use a **unit root test**. These are statistical hypothesis tests of stationarity that are designed for determining whether differencing is required.

A number of unit root tests are available, which are based on different assumptions and may lead to conflicting answers. In our analysis, we use the **Kwiatkowski-Phillips-Schmidt-Shin (KPSS) test**. 

In this test, **the null hypothesis is that the data is stationary**, and we look for evidence that the null hypothesis is false.^[Hyndman, R.J., & Athanasopoulos, G. (2019) Forecasting: principles and practice, 3rd edition, OTexts: Melbourne, Australia. OTexts.com/fpp3.]

```{r, message = FALSE, warning = FALSE}
# Run the test
kpss.test(chicago_sales$Median_price)
```

For this test, we do NOT want to reject the null hypothesis. In other words, we want the p-value to be greater than 0.05 not less than 0.05.^[0.05 will be the threshold of this project]. 

**KPSS demonstrates us: our p-value is small - 0.01. Hence, our data is non-stationary.**

#### Augmented Dickey-Fuller Test

It is one of statistical tests to determine the required order of differencing. Null hypothesis is that the data are non-stationary and non-seasonal.^[Hyndman, R.J., Forecasting: Principles & Practice. Source: https://robjhyndman.com/uwafiles/fpp-notes.pdf. Retrieved on October 28, 2020]

```{r, message = FALSE, warning = FALSE}
# Run ADF test for train data
adf.test(chicago_sales$Median_price)
```

We want to REJECT the null hypothesis for this test, so we want a p-value of less that 0.05 (or smaller). Here the p-value is slightly above 0.05, but still we can consider it non-stationary. 

### Holt-Winters

<font color='red'>Problems/Next steps: 
Problem:

Here we can do HW method:

- Linear trend with multiplicative seasonality

- Linear trend with multiplicative seasonality and damping

But data in `tsibble` format does not work well and so far I failed to apply his [code](https://otexts.com/fpp2/holt-winters.html).

This project can be very tricky because of different packages and data formats - `ts` vs `tsibble`. 

</font>

### Box-Cox transformation

First, what is the **Box-Cox transformation** and why do we use it? 

If the data show variation that increases or decreases with the level of the series, then a transformation can be useful. 

A useful family of transformations, that includes both logarithms and power transformations, is the family of Box-Cox transformations, which depend on the parameter Î» and are defined as follows:

<center>
![](Images/boxcox.png)
</center>

We can see that our data has an upwarding trend. Hence, we need to apply the transformation and stabilize the variance. 

The `BoxCox.lambda()` function will choose a value of lambda for you.^[Hyndman, R.J., & Athanasopoulos, G. (2019) Forecasting: principles and practice, 3rd edition, OTexts: Melbourne, Australia. OTexts.com/fpp3. Accessed on October 18, 2020.]

```{r, message = FALSE, warning = FALSE}
# Apply Box-Cox transformation
chicago_sales_bc <- chicago_sales %>% mutate(Median_price_bc = BoxCox(Median_price, BoxCox.lambda(Median_price)))

# Print
kable(head(chicago_sales_bc, n = 5)) %>% kable_styling() 
```

#### Plot Box-Cox data

```{r, message = FALSE, warning = FALSE}
# Plot BC data
chicago_sales_bc %>% autoplot(Median_price_bc, color = "#1277e1", size = 1) +
                     labs(title = "Median Sale Price (Box-Cox transformed) in Chicago Metro Area", 
                     subtitle = "February 2008 - August 2020") +
                     xlab("Weekly data by year") + ylab("Median Sale Price")
```

#### Plot ACF and PACF

```{r, message = FALSE, warning = FALSE}
# Plot ACF 
ggAcf(chicago_sales_bc$Median_price_bc, color = "#1277e1", size = 1) + 
      labs(title = "ACF plot for Median Sale Price (Box-Cox transformed) in Chicago Metro Area", 
           subtitle = "February 2008 - August 2020")
```

```{r, message = FALSE, warning = FALSE}
# Plot ACF 
ggPacf(chicago_sales_bc$Median_price_bc, color = "#1277e1", size = 1) + 
      labs(title = "PACF plot for Median Sale Price (Box-Cox transformed) in Chicago Metro Area", 
           subtitle = "February 2008 - August 2020")
```

#### KPSS and ADF test for B-C data

```{r, message = FALSE, warning = FALSE}
# Run the test
kpss.test(chicago_sales_bc$Median_price_bc)
```

```{r, message = FALSE, warning = FALSE}
# Run ADF test for train data
adf.test(chicago_sales_bc$Median_price_bc)
```

Here our p-value change, but it is even increased instead of decreasing. 

<font color='red'>Problems/Next steps: 

- Differencing with `diff()` (1 and 2 order) to address the linear trend and differencing with 12-24-etc for addressing the periodicity

- If we get stationary data at a certain stage - start from `auto.arima()` and maybe some manual models (using EACF) 

- Check residuals everywhere

- What are we doing with Sarima?

</font>












